{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'princeton-nlp/Sheared-LLaMA-1.3B'\n",
    "dataset_name = 'tab'\n",
    "target_epsilon = 'inf'\n",
    "model_config = f'{model_name.replace(\"/\", \"_\")}_{dataset_name}_DP_{target_epsilon}'\n",
    "synthetic_data_path = f'./data/synthetic/{model_config}_outputs-final.csv'# Path to the CSV file where the outputs are saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream Utility Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "2025-03-23 21:34:43.719124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742780083.737107  127092 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742780083.742749  127092 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-23 21:34:43.762190: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kramesh3/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/kramesh3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from transformers import TrainingArguments as HfTrainingArguments\n",
    "from syntheval.eval.downstream.classify.train_classifier import TrainingArguments, ModelArguments, Classifier, Arguments\n",
    "from syntheval.utils.utils import create_classification_dataset\n",
    "from syntheval.utils.filtering import process_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification: Creating the dataset\n",
    "\n",
    "Filtering data and creating a structured format out of raw synthetic text.\n",
    "\n",
    "We have assumed that the synthetic text is generated with labels (the labels typically serve as control codes in most setups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from the original data\n",
    "# And creating a test set for evaluating the model once it is trained\n",
    "from datasets import load_from_disk, concatenate_datasets\n",
    "from syntheval.utils.utils import encode_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to pd.Dataframe format...\n",
      "Saving label mapping to./data/benchmark/classification/data/tab-mapping.json...\n"
     ]
    }
   ],
   "source": [
    "tab_data = load_from_disk('./data/generator/data/tab/')\n",
    "col_names = [i for i in tab_data['train'].column_names if i not in ['country', 'text', 'year']]\n",
    "tab_data = tab_data.remove_columns(col_names)\n",
    "tab_data['train'] = concatenate_datasets([tab_data['train'], tab_data['validation'], tab_data['test']])\n",
    "\n",
    "_, _ = encode_labels(tab_data['train'], label_column = 'country', json_mapping_exists = False, \n",
    "                                json_mapping_path = f'./data/benchmark/classification/data/{dataset_name}-mapping.json', multilabel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to pd.Dataframe format...\n",
      "Label mapping already exists.\n",
      "Saving test file to: ./data/benchmark/classification/data/test/tab/test.csv\n"
     ]
    }
   ],
   "source": [
    "tab_data = load_from_disk('./data/generator/data/tab/')\n",
    "df, _ = encode_labels(tab_data['validation'], label_column = 'country', json_mapping_exists = True, \n",
    "                                json_mapping_path = f'./data/benchmark/classification/data/{dataset_name}-mapping.json', multilabel=False)\n",
    "test_file_path = f'./data/benchmark/classification/data/test/{dataset_name}/test.csv'\n",
    "print(f\"Saving test file to: {test_file_path}\")\n",
    "df.to_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping already exists.\n",
      "Data saved to ./data/benchmark/classification/data/princeton-nlp_Sheared-LLaMA-1.3B_tab_DP_inf\n",
      "Train: 1577 samples, Validation: 338 samples, Test: 339 samples\n"
     ]
    }
   ],
   "source": [
    "# Use this mapping for converting the synthetic data to a structured format\n",
    "df = pd.read_csv(synthetic_data_path)\n",
    "df = process_df(df, text_column = 'output_text')\n",
    "_, _, _ = create_classification_dataset(df, label_column = 'country', json_mapping_path = f'./data/benchmark/classification/data/{dataset_name}-mapping.json', json_mapping_exists = True,\n",
    "                                        output_dir = f'./data/benchmark/classification/data/{model_config}', multilabel = False, train_ratio = 0.7, test_ratio = 0.15, val_ratio = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 17\n"
     ]
    }
   ],
   "source": [
    "with open(f'./data/benchmark/classification/data/{dataset_name}-mapping.json') as f:\n",
    "    data = json.load(f)\n",
    "    n_labels_task = len(data)\n",
    "print(f\"Number of labels: {n_labels_task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification: Training the model\n",
    "\n",
    "This can also be run as a script. Sample script provided in eval.downstream.classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\n",
      "Loading training and validation data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241420f6e42044fea0536e098661cc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8cb45a0e87470d9ba3a6b213d064f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:778: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model for fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655b5e8da1af41429fd86d9ffc80684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1577 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f77af325d84966b876fe5686eb8339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/338 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [99/99 00:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.717368</td>\n",
       "      <td>0.313510</td>\n",
       "      <td>0.380090</td>\n",
       "      <td>0.340342</td>\n",
       "      <td>0.849112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.236020</td>\n",
       "      <td>0.748720</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.758321</td>\n",
       "      <td>0.982249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.161291</td>\n",
       "      <td>0.896011</td>\n",
       "      <td>0.918552</td>\n",
       "      <td>0.904642</td>\n",
       "      <td>0.994083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kramesh3/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/home/kramesh3/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "        train_args, model_args = TrainingArguments(), ModelArguments()\n",
    "\n",
    "        model_args.model_name = 'bert-base-uncased'\n",
    "        model_args.text_field = 'output_text'\n",
    "        model_args.label_field = 'Label'\n",
    "        model_args.path_to_dataset = f'./data/benchmark/classification/data/{model_config}'\n",
    "        model_args.path_to_model = f'./data/benchmark/classification/models/{model_args.model_name}_{model_config}'\n",
    "        model_args.n_labels = n_labels_task\n",
    "        model_args.is_train = True\n",
    "        model_args.problem_type = 'single_label_classification'\n",
    "        args = Arguments(train=train_args, model=model_args)\n",
    "\n",
    "        print(\"Training:\\n\")\n",
    "        obj = Classifier(args = args)\n",
    "        obj.finetune_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification: Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "\n",
      "Loading test data\n",
      "Checkpoint exists:  ./data/benchmark/classification/models/bert-base-uncased_princeton-nlp_Sheared-LLaMA-1.3B_tab_DP_inf \n",
      "Loading model from the checkpoint...\n",
      "Preprocessing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4b7722b4b64998962a48232dd8a2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/127 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation begins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file!\n",
      "Evaluation results:  {'eval_loss': 0.1836952269077301, 'eval_precision': 1.0, 'eval_recall': 1.0, 'eval_f1': 1.0, 'eval_accuracy': 1.0, 'eval_runtime': 0.4263, 'eval_samples_per_second': 297.888, 'eval_steps_per_second': 7.037}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "        train_args, model_args = TrainingArguments(), ModelArguments()\n",
    "        model_args.is_train = False\n",
    "        model_args.is_test = True\n",
    "        model_args.text_field = 'text'\n",
    "        model_args.label_field = 'Label'\n",
    "\n",
    "        model_args.model_name = 'bert-base-uncased'\n",
    "        model_args.path_to_model = f'./data/benchmark/classification/models/{model_args.model_name}_{model_config}'\n",
    "        model_args.path_to_dataset = f'./data/benchmark/classification/data/test/{dataset_name}/test.csv'\n",
    "        model_args.path_to_output_csv = f'./data/benchmark/classification/test-results/{model_args.model_name}_{model_config}_test_outputs.csv'\n",
    "        model_args.path_to_aggregated_results = './data/benchmark/classification/compiled_benchmark_results.csv'\n",
    "\n",
    "        model_args.n_labels = n_labels_task\n",
    "        model_args.problem_type = \"single_label_classification\"\n",
    "        model_args.retain_columns = ['country', 'year']\n",
    "\n",
    "        args = Arguments(train=train_args, model=model_args)\n",
    "        print(\"Testing:\\n\")\n",
    "        obj = Classifier(args = args)\n",
    "        obj.test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification: Fairness auditing of the trained classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "+-----------+--------+-------+----------+---------------+---------------+\n",
      "| Precision | Recall |  F1   | Accuracy | F1-micro-diff | F1-macro-diff |\n",
      "+-----------+--------+-------+----------+---------------+---------------+\n",
      "|   1.000   | 1.000  | 1.000 |  1.000   |     0.00      |     0.00      |\n",
      "+-----------+--------+-------+----------+---------------+---------------+\n",
      "\n",
      "Fairness Results:\n",
      "+---+----------+------------+----------------+----------+----------+\n",
      "|   | Accuracy | Group Type | Num of Samples | f1_macro | f1_micro |\n",
      "+---+----------+------------+----------------+----------+----------+\n",
      "| 0 |   1.0    |    DNK     |       4        |   1.0    |   1.0    |\n",
      "| 1 |   1.0    |    GBR     |       61       |   1.0    |   1.0    |\n",
      "| 2 |   1.0    |    IRL     |       1        |   1.0    |   1.0    |\n",
      "| 3 |   1.0    |    NOR     |       1        |   1.0    |   1.0    |\n",
      "| 4 |   1.0    |    POL     |       7        |   1.0    |   1.0    |\n",
      "| 5 |   1.0    |    SWE     |       11       |   1.0    |   1.0    |\n",
      "| 6 |   1.0    |    TUR     |       42       |   1.0    |   1.0    |\n",
      "+---+----------+------------+----------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from syntheval.eval.downstream.classify.visualize import tabulate_results\n",
    "\n",
    "path_to_test_output = f'./data/benchmark/classification/test-results/{model_args.model_name}_{model_config}_test_outputs.csv'\n",
    "tabulate_results([path_to_test_output], n_labels = n_labels_task, print_fairness=True, subgroup_type=\"country\", problem_type = \"multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Analysis of Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /home/kramesh3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/kramesh3/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/kramesh3/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from syntheval.eval.descriptive.descriptor import TextDescriptor\n",
    "from syntheval.eval.descriptive.arguments import TextDescriptorArgs\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "synth_df = pd.read_csv(synthetic_data_path)\n",
    "real_texts = load_from_disk('./data/generator/data/tab')\n",
    "len_samples = len(synth_df) if len(synth_df)<len(real_texts['train']) else len(real_texts['train'])\n",
    "synth_df = synth_df.head(len_samples)\n",
    "real_texts = real_texts['train'].select(range(len_samples))\n",
    "real_texts = real_texts[ 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text length and distributional comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_analyze = TextDescriptor(texts = synth_df['output_text'].tolist(), args = TextDescriptorArgs(produce_plot=True), reference_texts = real_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing text length...\n",
      "+-------------------+-----------------------+-----------------------+--------------+\n",
      "| Metric            |   Text Distribution 1 |   Text Distribution 2 |   Difference |\n",
      "+===================+=======================+=======================+==============+\n",
      "| Avg. Length       |               181.798 |              1343.42  |    -1161.62  |\n",
      "+-------------------+-----------------------+-----------------------+--------------+\n",
      "| Min Length        |               146     |               185     |      -39     |\n",
      "+-------------------+-----------------------+-----------------------+--------------+\n",
      "| Max Length        |               219     |              5144     |    -4925     |\n",
      "+-------------------+-----------------------+-----------------------+--------------+\n",
      "| Avg. Unique Words |               114.62  |               487.966 |     -373.346 |\n",
      "+-------------------+-----------------------+-----------------------+--------------+\n",
      "Comparing distributions...\n",
      "Jaccard similarity: 0.148\n",
      "Cosine similarity: 0.416\n"
     ]
    }
   ],
   "source": [
    "desc_analyze._compare_to_reference_distribution(metrics = ['text-length', 'jaccard', 'cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "tm = desc_analyze._topic_modeling_display(num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el90833140358965962672408206354\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el90833140358965962672408206354_data = {\"mdsDat\": {\"x\": [-0.041290723337209484, -0.012242574835897333, 0.053533298173106814], \"y\": [0.026389687179283406, -0.03804398406686801, 0.011654296887584603], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [42.50364484666932, 31.992285566878962, 25.50406958645172]}, \"tinfo\": {\"Term\": [\"commission\", \"kingdom\", \"united\", \"decided\", \"that\", \"and\", \",\", \"art\", \"turkish\", \"section\", \"referred\", \"european\", \"admissibility\", \"same\", \"to\", \"rule\", \"1\", \"merits\", \"(\", \"ireland\", \"article\", \"time\", \"born\", \"former\", \")\", \"great\", \"britain\", \"northern\", \"chamber\", \"48\", \"admissibility\", \"diyarbak\\u0131r\", \"lives\", \"same\", \"i\\u0307stanbul\", \"examine\", \"notice\", \"istanbul\", \"i\\u0307zmir\", \"give\", \"born\", \"1960\", \"izmir\", \"mehmet\", \"1953\", \"circumstances\", \"ahmet\", \"1956\", \"1955\", \"1972\", \"turkish\", \"turkey\", \"arrested\", \"1963\", \"kemal\", \"communicate\", \"military\", \"1952\", \"merits\", \"district\", \"decided\", \"time\", \"ankara\", \"suspicion\", \"illegal\", \"29\", \"provisions\", \"prosecutor\", \"i.\", \"at\", \"republic\", \"applying\", \"designate\", \"facts\", \"3\", \"the\", \"purposes\", \"it\", \"applicants\", \"on\", \"of\", \"government\", \"applicant\", \".\", \"in\", \"application\", \"\\u201d\", \",\", \"to\", \"convention\", \"\\u201c\", \")\", \"(\", \"and\", \"mr\", \"by\", \"article\", \"court\", \"was\", \"case\", \"a\", \"under\", \"for\", \"an\", \"represented\", \"with\", \"\\u00a7\", \"sections\", \"psychiatric\", \"undue\", \"composed\", \"newly\", \"changed\", \"composition\", \"tufan\", \"religion\", \"forced\", \"licence\", \"influence\", \"test\", \"marry\", \"parole\", \"need\", \"army\", \"means\", \"photographs\", \"registry\", \"seen\", \"sign\", \"reform\", \"outcome\", \"presiding\", \"1.\", \"change\", \"oslo\", \"pemberton\", \"media\", \"provided\", \"consider\", \"assigned\", \"exercise\", \"this\", \"52\", \"constituted\", \"26\", \"admissible\", \"allocated\", \"would\", \"chamber\", \"27\", \"section\", \"rule\", \"declared\", \"that\", \"rules\", \"fourth\", \"refused\", \"1\", \"had\", \"his\", \"been\", \"\\u00a7\", \"court\", \"the\", \",\", \"of\", \"(\", \")\", \"a\", \"applicant\", \"was\", \".\", \"by\", \"in\", \"\\u201d\", \"convention\", \"\\u201c\", \"application\", \"and\", \"case\", \"government\", \"represented\", \"to\", \"mr\", \"article\", \"on\", \"48\", \"art\", \"para\", \"whereby\", \"recognised\", \"32-1\", \"compulsory\", \"32\", \"three-month\", \"object\", \"46\", \"47\", \"enquiry\", \"obligations\", \"33\", \"disclosed\", \"jurisdiction\", \"44\", \"whether\", \"laid\", \"declaration\", \"1991.\", \"down\", \"piggott\", \"sir\", \"response\", \"referred\", \"commission\", \"1990.\", \"representative\", \"d\", \"obtain\", \"european\", \"request\", \"respondent\", \"former\", \"period\", \"articles\", \"united\", \"kingdom\", \"25\", \"and\", \"the\", \"ireland\", \",\", \"to\", \"great\", \".\", \"of\", \"article\", \"(\", \")\", \"by\", \"britain\", \"northern\", \"\\u201c\", \"in\", \"a\", \"convention\", \"was\", \"under\", \"court\", \"human\", \"mr\", \"on\", \"case\", \"\\u201d\", \"rights\", \"application\", \"with\", \"no\", \"government\"], \"Freq\": [801.0, 1481.0, 1334.0, 931.0, 2394.0, 4900.0, 9766.0, 323.0, 626.0, 1207.0, 283.0, 320.0, 405.0, 430.0, 4459.0, 1253.0, 1618.0, 510.0, 6667.0, 627.0, 3276.0, 545.0, 404.0, 264.0, 6519.0, 603.0, 603.0, 611.0, 625.0, 178.0, 402.0971564920111, 84.01521117345393, 265.1874741873294, 423.15367293282304, 56.32467926198923, 313.87677854727605, 228.82540702558882, 169.30613796384517, 23.4983835719622, 236.67211351840893, 389.4694489839776, 19.01759589069423, 18.962997753443748, 25.81619349655404, 14.568621151797485, 367.5881911239182, 14.465641006313778, 11.89820840493105, 11.889045451174322, 11.885832412857646, 590.156151441401, 308.12997818809606, 83.22017146335025, 15.248362669886083, 10.995684753083262, 162.90243334846465, 10.991140646880561, 11.811651201768543, 477.34958414249263, 42.3176629444957, 861.5991643329014, 503.86465798181825, 85.15244870197867, 51.50226314023504, 32.10761140852471, 462.8518715383446, 253.7106961515517, 31.972720904975912, 294.5528102993707, 519.6047767539249, 427.33969919984025, 48.80616624180634, 189.38852433928398, 471.87570896590887, 477.8133634651832, 14634.72857033388, 163.88564658750042, 444.0975902681723, 396.1317418791466, 1687.83823230291, 5771.565927777334, 1617.59047210076, 1764.3752034476904, 3808.237403137267, 2532.177700532562, 1543.9682860096539, 1738.0374396078498, 3666.165817736029, 2003.2220383526292, 1798.5252490896357, 1744.5556110226855, 2518.613566191844, 2534.534380998588, 1978.703489081618, 1167.7170045683695, 1672.176583551794, 1367.3824680745304, 1449.184670134603, 1332.8622159225963, 1096.5765135109766, 1361.5369889766253, 927.4421227745804, 896.4380262686933, 883.0128268624001, 814.7618599615132, 679.5174351194091, 738.2283823450647, 83.09103427470643, 9.07225899203234, 7.006028432039165, 57.9445510370932, 62.9544981560826, 84.749630308477, 84.99292544667257, 5.871498985542037, 5.862638121185885, 4.804906730430155, 7.679171571646688, 4.792705817047187, 4.792279777485477, 4.789895156941634, 4.720051217280576, 5.633640592554563, 4.649128904485576, 4.6408603236150645, 3.703429483698961, 5.5191016894968135, 3.683718200801966, 3.682143624320929, 4.605884940812778, 3.6808525474592195, 5.485046969337895, 231.27721196489856, 3.65121972604502, 4.565726603431503, 3.6524494886077887, 3.6474906156677105, 306.83244835838474, 332.902691559622, 87.87413618658917, 9.115101252231153, 97.84071100452445, 339.3039751648933, 316.94798784586123, 292.0009113505257, 171.4485142403738, 391.2526856108303, 341.49539119224374, 450.18840441401153, 353.2416027911197, 805.1581146907149, 787.4587372527453, 202.58802646087838, 1409.5581755803914, 369.961407818669, 348.1887988734895, 28.707890789940212, 889.7613087543493, 761.1801923111408, 512.2563357337862, 534.7270730793383, 1064.768186323713, 1585.376009973877, 8950.020171046186, 3435.4962905462785, 3940.291548405537, 2331.8129376402353, 2237.1710479725634, 1428.7771160348063, 1189.233027357643, 1183.3195072178232, 2262.0975127497563, 1425.5353923876683, 1561.6610854026505, 1171.2117106596536, 1250.5056983138247, 1118.0592071010267, 943.1729657308813, 1186.9462796054577, 827.4042065586482, 862.6654151309849, 689.3339324490892, 993.7304559980726, 753.2960381886498, 776.2760609506876, 716.3400973367505, 174.9644664137887, 316.2054997870773, 104.75428685829559, 69.80951752469521, 71.51984145223554, 49.48349829031204, 65.86818801893385, 112.34069429699991, 113.20048821506423, 101.14411184987719, 95.50763219896294, 173.64681449667117, 40.87121577339518, 76.99435186065172, 26.15585778150426, 79.92867273388951, 75.47466772298978, 124.06469065213254, 101.89142466375063, 124.80886712097478, 91.80482616724522, 18.635501043524442, 124.87190846236022, 15.954079230938591, 17.69309789361011, 51.989700004207606, 263.46123870631493, 740.9126059883769, 12.24793932089079, 15.681402652647753, 34.65613287101838, 108.24935236026045, 279.05611371146955, 169.99830190310277, 85.3020864061972, 223.079546729171, 133.94096052954058, 145.9603860739616, 717.5518181826294, 772.3873199544256, 298.2505453024048, 1734.9334482983347, 6627.805461770454, 357.30042403710013, 2665.3227036006174, 1462.4208307081515, 337.5181978493667, 2299.994010291677, 3075.71104828303, 1132.486750523739, 1801.1495771137245, 1763.4596431813773, 1278.6087591491025, 332.15709574225855, 333.8271148142437, 971.4955961707225, 1140.3500270842205, 888.0192173263625, 908.654335860575, 817.95665561451, 525.3671727805005, 708.660852462619, 458.6734165110022, 563.4872616745561, 605.0289820588948, 553.4473455372554, 611.8826296471738, 462.1870582056454, 525.0195141744715, 434.0251953515741, 427.2961308055112, 451.7554295053736], \"Total\": [801.0, 1481.0, 1334.0, 931.0, 2394.0, 4900.0, 9766.0, 323.0, 626.0, 1207.0, 283.0, 320.0, 405.0, 430.0, 4459.0, 1253.0, 1618.0, 510.0, 6667.0, 627.0, 3276.0, 545.0, 404.0, 264.0, 6519.0, 603.0, 603.0, 611.0, 625.0, 178.0, 405.88813075775124, 85.20392793397538, 269.01296165503163, 430.3092636124828, 57.43962075587525, 320.3068517057467, 234.42481334418957, 174.64696982197424, 24.254688682551716, 244.41047592188553, 404.51635285459605, 19.775305779673158, 19.793875060517365, 27.02535076345778, 15.29817868615746, 388.2746296854461, 15.323138796462546, 12.611738972596461, 12.61239601137542, 12.613009528266538, 626.6116326354703, 327.90962657611453, 88.58478477520156, 16.239015125659645, 11.716070715646557, 173.58016943093415, 11.717269978027392, 12.61458042401735, 510.40711649655486, 45.260382608483326, 931.4060521785836, 545.3555482398666, 91.64579107061171, 55.24182963229892, 34.34752366029941, 510.6175337457449, 279.4885301930389, 34.283251798858785, 330.8659861330206, 597.343438294, 508.08661650812985, 53.08408303711688, 224.04476877721217, 601.3032194761283, 657.5603796722363, 30212.55420315052, 207.46702969360146, 645.066460762158, 568.704392118002, 3009.2073116985557, 12787.568524465902, 2932.0113167371187, 3348.3773514800355, 8370.3289261787, 5234.188813019433, 3012.160765915007, 3521.1317799146773, 9766.984811882925, 4459.373325058853, 3957.685283264035, 3834.1104142944346, 6519.244257345785, 6667.496895752548, 4900.58321698541, 2484.5003044315754, 4376.320735088565, 3276.1452795489568, 3743.221532571099, 3334.1383787549294, 2477.4280656068804, 3678.3333223377945, 1908.6534826088387, 1789.2829974881224, 1779.5736155323818, 1874.9069458354156, 1553.1523486749325, 2164.9883521161955, 90.25355214676904, 9.901453923880199, 7.687001906958687, 63.61432047338146, 69.17319311535157, 93.23335264507351, 94.18943517773054, 6.5602576130702825, 6.561387671999734, 5.453184818374515, 8.725742538428788, 5.4516632630133905, 5.451817714197243, 5.450383492884053, 5.43721516493729, 6.51946107160173, 5.416767090636298, 5.4199947586464505, 4.3370766729787364, 6.488819129619398, 4.3318885703052095, 4.33130783074784, 5.418023781988005, 4.33172048441266, 6.476026597482993, 273.5842860767718, 4.322988835003361, 5.406213750269699, 4.325659824801847, 4.32412819702602, 366.6611596781416, 404.58580495182395, 106.87719769210103, 10.841688858339243, 121.43854166748754, 432.13510429989185, 403.98678974020055, 387.88679754963755, 224.88478005336773, 530.2544876025881, 461.3724473497994, 625.1144577297246, 503.45464891633645, 1207.0822348256088, 1253.4902467164918, 296.9461170338966, 2394.690063982798, 581.3912662963551, 545.0788105492737, 37.32165978644335, 1618.8904281273851, 1386.385616871236, 904.3395350182961, 997.7740842908835, 2164.9883521161955, 3743.221532571099, 30212.55420315052, 9766.984811882925, 12787.568524465902, 6667.496895752548, 6519.244257345785, 3678.3333223377945, 3348.3773514800355, 3334.1383787549294, 8370.3289261787, 4376.320735088565, 5234.188813019433, 3521.1317799146773, 3957.685283264035, 3834.1104142944346, 3012.160765915007, 4900.58321698541, 2477.4280656068804, 2932.0113167371187, 1874.9069458354156, 4459.373325058853, 2484.5003044315754, 3276.1452795489568, 3009.2073116985557, 178.68217419536577, 323.30323389302674, 107.77018148239048, 71.8604711115388, 73.7411459714312, 51.07369066834236, 68.06790893908136, 116.22881380219603, 117.17376024018249, 104.9105652904615, 99.2110505005946, 180.40619321133863, 42.55224196501875, 80.30787924933526, 27.46524931496454, 84.04151201815463, 79.49824104559423, 131.20569233516298, 107.75939634214535, 132.16622457946647, 97.23202342891364, 19.87030766394194, 133.18151760284186, 17.03777160446077, 18.934138123791463, 55.72960890631117, 283.2472956025375, 801.6099199396651, 13.268147382403194, 17.04079729854894, 37.734573312723924, 121.49525665066784, 320.06832442825765, 193.7773077385881, 96.368699596159, 264.485878660594, 161.1067103953561, 179.77463226341058, 1334.5557565488086, 1481.61513194403, 481.27035384651043, 4900.58321698541, 30212.55420315052, 627.8447213553272, 9766.984811882925, 4459.373325058853, 603.6144534516669, 8370.3289261787, 12787.568524465902, 3276.1452795489568, 6667.496895752548, 6519.244257345785, 4376.320735088565, 603.073062519868, 611.823701198329, 3834.1104142944346, 5234.188813019433, 3678.3333223377945, 3957.685283264035, 3334.1383787549294, 1908.6534826088387, 3743.221532571099, 1490.0825633108054, 2484.5003044315754, 3009.2073116985557, 2477.4280656068804, 3521.1317799146773, 1565.0840415913171, 3012.160765915007, 1553.1523486749325, 1542.91031996143, 2932.0113167371187], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.6596, -7.2253, -6.0759, -5.6086, -7.6252, -5.9073, -6.2234, -6.5246, -8.4994, -6.1897, -5.6915, -8.711, -8.7138, -8.4053, -8.9775, -5.7494, -8.9846, -9.1799, -9.1807, -9.181, -5.2759, -5.9258, -7.2348, -8.9319, -9.2588, -6.5632, -9.2592, -9.1872, -5.4881, -7.9111, -4.8975, -5.434, -7.2119, -7.7147, -8.1872, -5.5189, -6.1201, -8.1914, -5.9709, -5.4033, -5.5988, -7.7685, -6.4125, -5.4996, -5.4871, -2.0652, -6.5572, -5.5603, -5.6746, -4.2251, -2.9956, -4.2676, -4.1808, -3.4114, -3.8195, -4.3142, -4.1958, -3.4494, -4.0538, -4.1616, -4.1921, -3.8249, -3.8186, -4.0661, -4.5935, -4.2345, -4.4357, -4.3776, -4.4612, -4.6564, -4.44, -4.8239, -4.8579, -4.873, -4.9534, -5.1349, -5.0521, -6.9523, -9.167, -9.4255, -7.3128, -7.2298, -6.9325, -6.9297, -9.6021, -9.6036, -9.8026, -9.3337, -9.8051, -9.8052, -9.8057, -9.8204, -9.6435, -9.8356, -9.8373, -10.063, -9.664, -10.0683, -10.0687, -9.8449, -10.0691, -9.6702, -5.9286, -10.0772, -9.8537, -10.0768, -10.0782, -5.6459, -5.5644, -6.8963, -9.1623, -6.7889, -5.5453, -5.6135, -5.6955, -6.228, -5.4029, -5.5389, -5.2626, -5.5051, -4.6812, -4.7034, -6.0611, -4.1212, -5.4588, -5.5195, -8.0151, -4.5813, -4.7374, -5.1334, -5.0905, -4.4017, -4.0037, -2.2728, -3.2303, -3.0932, -3.6178, -3.6593, -4.1077, -4.2912, -4.2962, -3.6482, -4.1099, -4.0187, -4.3064, -4.2409, -4.3529, -4.523, -4.2931, -4.6539, -4.6122, -4.8365, -4.4708, -4.7478, -4.7177, -4.7981, -5.981, -5.3892, -6.494, -6.8998, -6.8756, -7.2439, -6.9579, -6.424, -6.4164, -6.529, -6.5864, -5.9886, -7.4352, -6.8018, -7.8815, -6.7644, -6.8218, -6.3248, -6.5217, -6.3188, -6.6259, -8.2205, -6.3183, -8.3759, -8.2724, -7.1945, -5.5717, -4.5377, -8.6402, -8.3931, -7.6001, -6.4611, -5.5142, -6.0098, -6.6994, -5.7381, -6.2482, -6.1622, -4.5697, -4.4961, -5.4476, -3.6869, -2.3466, -5.267, -3.2575, -3.8577, -5.324, -3.4049, -3.1143, -4.1134, -3.6494, -3.6705, -3.9921, -5.34, -5.335, -4.2667, -4.1065, -4.3566, -4.3336, -4.4388, -4.8815, -4.5822, -5.0172, -4.8114, -4.7403, -4.8294, -4.729, -5.0096, -4.8821, -5.0725, -5.0881, -5.0324], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.8462, 0.8415, 0.8413, 0.8388, 0.836, 0.8353, 0.8314, 0.8245, 0.8239, 0.8234, 0.8177, 0.8165, 0.8127, 0.8098, 0.8067, 0.8008, 0.798, 0.7973, 0.7965, 0.7962, 0.7956, 0.7934, 0.7931, 0.7926, 0.7921, 0.7921, 0.7916, 0.7898, 0.7886, 0.7884, 0.7777, 0.7765, 0.7821, 0.7855, 0.7881, 0.7574, 0.7588, 0.7858, 0.7393, 0.7162, 0.6825, 0.7716, 0.6875, 0.6132, 0.5363, 0.1307, 0.6198, 0.4823, 0.494, 0.2774, 0.0601, 0.2608, 0.2149, 0.0681, 0.1294, 0.1873, 0.1496, -0.1243, 0.0553, 0.0669, 0.0681, -0.0955, -0.1117, -0.0513, 0.1006, -0.1065, -0.0182, -0.0934, -0.0613, 0.0406, -0.1383, 0.1339, 0.1644, 0.1548, 0.0222, 0.0289, -0.2203, 1.057, 1.0522, 1.0469, 1.0463, 1.0455, 1.0443, 1.0369, 1.0288, 1.0271, 1.0131, 1.0119, 1.0108, 1.0107, 1.0105, 0.9982, 0.9936, 0.9869, 0.9845, 0.9817, 0.9778, 0.9776, 0.9773, 0.9773, 0.9769, 0.9736, 0.9717, 0.9708, 0.9707, 0.9705, 0.9695, 0.9615, 0.9447, 0.9439, 0.9662, 0.9236, 0.8978, 0.897, 0.8557, 0.8684, 0.8357, 0.8388, 0.8114, 0.7853, 0.7348, 0.6748, 0.7573, 0.6097, 0.6877, 0.6915, 0.8773, 0.5411, 0.5401, 0.5713, 0.5159, 0.43, 0.2806, -0.0769, 0.0948, -0.0375, 0.0891, 0.0701, 0.194, 0.1045, 0.1038, -0.1687, 0.018, -0.0698, 0.0389, -0.0124, -0.0927, -0.0215, -0.2783, 0.043, -0.0837, 0.1391, -0.3616, -0.0537, -0.3002, -0.2956, 1.3453, 1.3441, 1.3379, 1.3374, 1.3357, 1.3347, 1.3335, 1.3323, 1.3318, 1.3298, 1.3283, 1.3281, 1.326, 1.3242, 1.3175, 1.3162, 1.3144, 1.3104, 1.3103, 1.3091, 1.3089, 1.3022, 1.3019, 1.3006, 1.2985, 1.2969, 1.2939, 1.2876, 1.2863, 1.2832, 1.2812, 1.2509, 1.2292, 1.2354, 1.2443, 1.1961, 1.1817, 1.158, 0.7458, 0.7149, 0.8878, 0.3279, -0.1507, 0.8026, 0.0676, 0.2514, 0.785, 0.0745, -0.0586, 0.3041, 0.0575, 0.0589, 0.1359, 0.7699, 0.7605, -0.0065, -0.1575, -0.0549, -0.1051, -0.0388, 0.0763, -0.298, 0.1881, -0.1173, -0.2378, -0.1325, -0.3837, 0.1466, -0.3806, 0.0914, 0.0824, -0.504]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 1, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 2, 1, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 2, 2, 2, 1, 2, 1, 2, 3, 1, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 1, 2, 3, 2, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3], \"Freq\": [0.3802026517050038, 0.34975644330416916, 0.27011636123105004, 0.38639448079608757, 0.34313793312459223, 0.27043011895335545, 0.37534613502621506, 0.35169502831834387, 0.27285800595877335, 0.45494030564202254, 0.27024027609302914, 0.27478012158000314, 0.21310892572208914, 0.5497592576598821, 0.2378172069652299, 0.12062096282364593, 0.8443467397655214, 0.03289662622463071, 0.9512801533337385, 0.9805088767575145, 0.9514449109571975, 0.9514944787609636, 0.9607942456965654, 0.9237013380385459, 0.06158008920256973, 0.9513986311599348, 0.07536847241584341, 0.9044216689901209, 0.05032634707587696, 0.9562005944416623, 0.17038240428611964, 0.20986125405973274, 0.6191945911861422, 0.18046502340941922, 0.7527969547935773, 0.0670298658377843, 0.17081975543400213, 0.7011555077697994, 0.12910795468848998, 0.906745204387252, 0.043085085305657765, 0.05091873717941372, 0.7269294421878962, 0.07147632590550444, 0.20074202169205502, 0.02581115561504008, 0.9636164762948296, 0.01957955234709213, 0.9593980650075143, 0.03640964582306363, 0.03640964582306363, 0.9466507913996545, 0.05335134379778741, 0.007621620542541058, 0.9450809472750912, 0.03023856702315656, 0.96763414474101, 0.03325828173188733, 0.005543046955314555, 0.9644901702247326, 0.01678958750927157, 0.9793926047075082, 0.08562137079778376, 0.7844768837959106, 0.12958910174799704, 0.3702763944009212, 0.3884911656379709, 0.24141368445522615, 0.9904206837719238, 0.0024637330442087656, 0.004927466088417531, 0.1912090270839832, 0.7603893867758402, 0.04446721560092633, 0.9136509292229343, 0.06526078065878102, 0.09806611960061834, 0.737381783920034, 0.16407216163949606, 0.49618627310106495, 0.30344347392364107, 0.20060985220507382, 0.40382948567035665, 0.2422160684642311, 0.3540394935007927, 0.9274839466932941, 0.06546945506070312, 0.5268223425356418, 0.3550973726048061, 0.11796758803944357, 0.6963195739093797, 0.021100593148769085, 0.2830996247459852, 0.512588842359142, 0.3130642994460304, 0.17429348590579635, 0.923063886508857, 0.07535215400072302, 0.9230598097236371, 0.9369554851956364, 0.04515448121424754, 0.011288620303561885, 0.018558428654583937, 0.003093071442430656, 0.9774105758080873, 0.41725866326300454, 0.23686373276670922, 0.34552802254112736, 0.11125040139531737, 0.07787528097672217, 0.8121279301858169, 0.08420879471342242, 0.8233748816423525, 0.09356532745935824, 0.8705209878677312, 0.08872617760959568, 0.041851970570564, 0.2936536482687207, 0.5361935215828177, 0.1703792498487458, 0.9616422111365831, 0.014832527678199226, 0.022248791517298836, 0.119388519359755, 0.32997660211932284, 0.5505137281588702, 0.38205609259719014, 0.32584449045669445, 0.2922546306410324, 0.4427979222602674, 0.3338139304550967, 0.22321536099355319, 0.12157773518151371, 0.7198681688379102, 0.15837099714434022, 0.9252857577636769, 0.07508042778047501, 0.9116909087629108, 0.010725775397210716, 0.9477827595847012, 0.0386324494395938, 0.012877483146531265, 0.06486945671020874, 0.011227405969074589, 0.9243897581204745, 0.9390473608499161, 0.046088214029443735, 0.0172830802610414, 0.07859865456068467, 0.9117443929039422, 0.015719730912136933, 0.08493521576920403, 0.9024366675477928, 0.021233803942301007, 0.029382421631167444, 0.9696199138285256, 0.09392321612599545, 0.8230639728935917, 0.08156489821468026, 0.0940624816579705, 0.7846791233046486, 0.12129109476948828, 0.45455862991619805, 0.3160938554892517, 0.22967970794542747, 0.3870997180882127, 0.4234320587783417, 0.18940904080368726, 0.0795026877642847, 0.927531357249988, 0.9254824981905142, 0.04724040594011905, 0.026841139738704008, 0.0514233873128795, 0.0102846774625759, 0.9461903265569829, 0.2559386893458672, 0.6836257097001454, 0.0639846723364668, 0.8435814013043959, 0.14282859704624692, 0.013390180973085648, 0.04759552635292807, 0.9519105270585614, 0.9279638743515124, 0.06628313388225089, 0.9858700418728547, 0.011736548117533984, 0.0525598455851402, 0.007508549369305743, 0.9385686711632178, 0.02350052438651946, 0.963521499847298, 0.10310298608570012, 0.02499466329350306, 0.8716888823609191, 0.9803099694178864, 0.009366018816094456, 0.012488025088125942, 0.8301289695357151, 0.09223655217063502, 0.7849617043647615, 0.04989163375199756, 0.16464239138159195, 0.5007592433717002, 0.3425953305656833, 0.15648726355365633, 0.9168953861883595, 0.13989404722616924, 0.018904600976509357, 0.8431452035523173, 0.2531743985075075, 0.638439787540671, 0.10824122834741262, 0.9696802033794413, 0.01636591060556019, 0.01636591060556019, 0.551839616294724, 0.29433719954409565, 0.15416038724673378, 0.11596806471368747, 0.3247105811983249, 0.5599600839032338, 0.279143115227474, 0.5489093299434308, 0.17239070940404724, 0.32509913435781834, 0.5661590367047721, 0.10836637811927277, 0.4087021853653979, 0.2832057836193726, 0.3080366224675166, 0.8915996577581078, 0.08160403647277596, 0.02720134549092532, 0.9316537726702903, 0.05822836079189314, 0.02911418039594657, 0.48374257988209096, 0.2984225552037228, 0.21779879189004095, 0.9171512910421883, 0.11308528619422399, 0.31695735144578274, 0.5686119319906756, 0.967666373898554, 0.02862918265972053, 0.6883011705110288, 0.03410501295324917, 0.2774907872105274, 0.9598928932263041, 0.9749367990782217, 0.01740958569782539, 0.9482702623408928, 0.037736683988761774, 0.012578894662920592, 0.9434170997190444, 0.938881325230458, 0.13498782220020905, 0.3442189466105331, 0.5210529936928069, 0.052963607171748854, 0.007566229595964122, 0.9457786994955152, 0.9168274178120009, 0.11460342722650012, 0.9850826457195856, 0.007434586005430835, 0.007434586005430835, 0.9173666415451193, 0.9225101171958814, 0.9250419547577373, 0.9620596686262365, 0.03700229494716294, 0.9345480981420048, 0.05093972861989963, 0.013714542320742209, 0.9387852307429597, 0.47011465360525473, 0.3030790532232507, 0.22660492292787535, 0.9203214704564366, 0.0578258689508477, 0.9107574359758512, 0.02891293447542385, 0.4154486438434243, 0.30785975947835653, 0.2767497206258068, 0.12421879023507103, 0.3301604687826888, 0.5459088939278122, 0.9768590480384656, 0.012797280105307408, 0.00853152007020494, 0.02859578529287327, 0.009531928430957756, 0.9627247715267334, 0.03735623488058717, 0.9588100286017373, 0.06584619202873239, 0.04938464402154929, 0.8889235923878872, 0.45137588032914017, 0.3081117409038136, 0.24054612056348493, 0.5609450679711407, 0.2379364150872848, 0.2010496244801778, 0.9248616926681017, 0.9234206164487462, 0.02783701352948168, 0.9742954735318589, 0.9195884011071075, 0.9247144162990752, 0.11172718973547394, 0.05586359486773697, 0.8317468569196392, 0.9222802135182845, 0.0586931215663311, 0.9390899450612976, 0.1544156721636482, 0.772078360818241, 0.9334003725126567, 0.029168761641020523, 0.029168761641020523, 0.09545597911358626, 0.8372853025105995, 0.06818284222399018, 0.908802947385947, 0.014311857439148772, 0.07513725155553105, 0.9089574186972598, 0.7904870486756574, 0.14942133237161817, 0.05784051575675542, 0.027121900177342517, 0.9763884063843306, 0.060018225289095055, 0.01059145152160501, 0.9285172500607058, 0.9228457092828372, 0.10717636951004395, 0.7770286789478186, 0.10717636951004395, 0.15411124582519456, 0.9246674749511673, 0.9144407097914033, 0.05868270025635197, 0.9389232041016315, 0.4346882397605363, 0.367484904533754, 0.19787648705663677, 0.8404078874082439, 0.15154896330312595, 0.005904505063758154, 0.09289013357685094, 0.030963377858950314, 0.8772957060035923, 0.0933913193569618, 0.020753626523769286, 0.8820291272601947, 0.05383134852145465, 0.017943782840484885, 0.933076707705214, 0.40509006746715864, 0.2996644189938445, 0.29519181572527964, 0.19944311545691967, 0.6278469274583831, 0.1723188517547786, 0.1290009058405255, 0.6364044688132593, 0.2339216425908196, 0.9830139292119325, 0.004647819996273912, 0.011619549990684782, 0.20711099276191264, 0.6668973966933587, 0.12592348359924288, 0.0553994815834957, 0.9196313942860286, 0.02215979263339828, 0.9233847858921667, 0.9235085928559742, 0.052814656440234906, 0.9506638159242282, 0.9413156723106889, 0.054306673402539744, 0.01810222446751325, 0.917125307946256, 0.23969698986654467, 0.5888027102993519, 0.17162972619364086, 0.4844012823806166, 0.2962344706051601, 0.219379002365475, 0.10705003388129833, 0.806992563105172, 0.09058079789956013, 0.02560300184828589, 0.9643797362854352, 0.9241677317241174, 0.04217432109058472, 0.03483965655309173, 0.4491662513977937, 0.22290127503215523, 0.32784875663683194, 0.9145982298082231, 0.9392831897495602, 0.05794279417286248, 0.0030496207459401303, 0.9415720508068368, 0.05585596911565981, 0.0015958848318759946, 0.4856827121562853, 0.2389118842969429, 0.2750630246839803, 0.9106281076453518, 0.12738321285251045, 0.3349429185004245, 0.5380067460476617, 0.39980344202083884, 0.3548143075098667, 0.24534074686650126, 0.027831712888378983, 0.9741099510932644, 0.04639966601264701, 0.009279933202529402, 0.9465531866579989, 0.43781925229687874, 0.28329481030974507, 0.2794316992600667, 0.09753508311666102, 0.7390991853951424, 0.1625584718611017, 0.3408794321127097, 0.49191950569110554, 0.16720644231002835, 0.4551251298069674, 0.2915930631084181, 0.2532530091934472, 0.4935912963876957, 0.3325635259321011, 0.1738077522377847], \"Term\": [\"(\", \"(\", \"(\", \")\", \")\", \")\", \",\", \",\", \",\", \".\", \".\", \".\", \"1\", \"1\", \"1\", \"1.\", \"1.\", \"1.\", \"1952\", \"1953\", \"1955\", \"1956\", \"1960\", \"1963\", \"1963\", \"1972\", \"1990.\", \"1990.\", \"1991.\", \"1991.\", \"25\", \"25\", \"25\", \"26\", \"26\", \"26\", \"27\", \"27\", \"27\", \"29\", \"29\", \"29\", \"3\", \"3\", \"3\", \"32\", \"32\", \"32-1\", \"32-1\", \"33\", \"33\", \"33\", \"44\", \"44\", \"44\", \"46\", \"46\", \"47\", \"47\", \"47\", \"48\", \"48\", \"52\", \"52\", \"52\", \"a\", \"a\", \"a\", \"admissibility\", \"admissibility\", \"admissibility\", \"admissible\", \"admissible\", \"admissible\", \"ahmet\", \"ahmet\", \"allocated\", \"allocated\", \"allocated\", \"an\", \"an\", \"an\", \"and\", \"and\", \"and\", \"ankara\", \"ankara\", \"applicant\", \"applicant\", \"applicant\", \"applicants\", \"applicants\", \"applicants\", \"application\", \"application\", \"application\", \"applying\", \"applying\", \"army\", \"arrested\", \"arrested\", \"arrested\", \"art\", \"art\", \"art\", \"article\", \"article\", \"article\", \"articles\", \"articles\", \"articles\", \"assigned\", \"assigned\", \"assigned\", \"at\", \"at\", \"at\", \"been\", \"been\", \"been\", \"born\", \"born\", \"born\", \"britain\", \"britain\", \"britain\", \"by\", \"by\", \"by\", \"case\", \"case\", \"case\", \"chamber\", \"chamber\", \"chamber\", \"change\", \"changed\", \"changed\", \"changed\", \"circumstances\", \"circumstances\", \"circumstances\", \"commission\", \"commission\", \"commission\", \"communicate\", \"communicate\", \"communicate\", \"composed\", \"composed\", \"composed\", \"composition\", \"composition\", \"composition\", \"compulsory\", \"compulsory\", \"consider\", \"consider\", \"consider\", \"constituted\", \"constituted\", \"constituted\", \"convention\", \"convention\", \"convention\", \"court\", \"court\", \"court\", \"d\", \"d\", \"decided\", \"decided\", \"decided\", \"declaration\", \"declaration\", \"declaration\", \"declared\", \"declared\", \"declared\", \"designate\", \"designate\", \"designate\", \"disclosed\", \"disclosed\", \"district\", \"district\", \"diyarbak\\u0131r\", \"diyarbak\\u0131r\", \"down\", \"down\", \"down\", \"enquiry\", \"enquiry\", \"european\", \"european\", \"european\", \"examine\", \"examine\", \"examine\", \"exercise\", \"exercise\", \"facts\", \"facts\", \"facts\", \"for\", \"for\", \"for\", \"forced\", \"former\", \"former\", \"former\", \"fourth\", \"fourth\", \"fourth\", \"give\", \"give\", \"give\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"had\", \"had\", \"had\", \"his\", \"his\", \"his\", \"human\", \"human\", \"human\", \"i.\", \"i.\", \"i.\", \"illegal\", \"illegal\", \"illegal\", \"in\", \"in\", \"in\", \"influence\", \"ireland\", \"ireland\", \"ireland\", \"istanbul\", \"istanbul\", \"it\", \"it\", \"it\", \"izmir\", \"i\\u0307stanbul\", \"i\\u0307stanbul\", \"i\\u0307zmir\", \"jurisdiction\", \"jurisdiction\", \"jurisdiction\", \"kemal\", \"kingdom\", \"kingdom\", \"kingdom\", \"laid\", \"laid\", \"laid\", \"licence\", \"licence\", \"lives\", \"lives\", \"lives\", \"marry\", \"means\", \"media\", \"mehmet\", \"mehmet\", \"merits\", \"merits\", \"merits\", \"military\", \"mr\", \"mr\", \"mr\", \"need\", \"newly\", \"newly\", \"newly\", \"no\", \"no\", \"no\", \"northern\", \"northern\", \"northern\", \"notice\", \"notice\", \"notice\", \"object\", \"object\", \"object\", \"obligations\", \"obligations\", \"obtain\", \"obtain\", \"obtain\", \"of\", \"of\", \"of\", \"on\", \"on\", \"on\", \"oslo\", \"outcome\", \"para\", \"para\", \"parole\", \"pemberton\", \"period\", \"period\", \"period\", \"photographs\", \"piggott\", \"piggott\", \"presiding\", \"presiding\", \"prosecutor\", \"prosecutor\", \"prosecutor\", \"provided\", \"provided\", \"provided\", \"provisions\", \"provisions\", \"provisions\", \"psychiatric\", \"purposes\", \"purposes\", \"purposes\", \"recognised\", \"recognised\", \"referred\", \"referred\", \"referred\", \"reform\", \"refused\", \"refused\", \"refused\", \"registry\", \"registry\", \"religion\", \"representative\", \"representative\", \"represented\", \"represented\", \"represented\", \"republic\", \"republic\", \"republic\", \"request\", \"request\", \"request\", \"respondent\", \"respondent\", \"respondent\", \"response\", \"response\", \"response\", \"rights\", \"rights\", \"rights\", \"rule\", \"rule\", \"rule\", \"rules\", \"rules\", \"rules\", \"same\", \"same\", \"same\", \"section\", \"section\", \"section\", \"sections\", \"sections\", \"sections\", \"seen\", \"sign\", \"sir\", \"sir\", \"suspicion\", \"suspicion\", \"suspicion\", \"test\", \"that\", \"that\", \"that\", \"the\", \"the\", \"the\", \"this\", \"this\", \"this\", \"three-month\", \"three-month\", \"time\", \"time\", \"time\", \"to\", \"to\", \"to\", \"tufan\", \"turkey\", \"turkey\", \"turkey\", \"turkish\", \"turkish\", \"turkish\", \"under\", \"under\", \"under\", \"undue\", \"united\", \"united\", \"united\", \"was\", \"was\", \"was\", \"whereby\", \"whereby\", \"whether\", \"whether\", \"whether\", \"with\", \"with\", \"with\", \"would\", \"would\", \"would\", \"\\u00a7\", \"\\u00a7\", \"\\u00a7\", \"\\u201c\", \"\\u201c\", \"\\u201c\", \"\\u201d\", \"\\u201d\", \"\\u201d\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el90833140358965962672408206354\", ldavis_el90833140358965962672408206354_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el90833140358965962672408206354\", ldavis_el90833140358965962672408206354_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el90833140358965962672408206354\", ldavis_el90833140358965962672408206354_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.041291  0.026390       1        1  42.503645\n",
       "1     -0.012243 -0.038044       2        1  31.992286\n",
       "0      0.053533  0.011654       3        1  25.504070, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "127   commission   801.000000   801.000000  Default  30.0000  30.0000\n",
       "350      kingdom  1481.000000  1481.000000  Default  29.0000  29.0000\n",
       "365       united  1334.000000  1334.000000  Default  28.0000  28.0000\n",
       "37       decided   931.000000   931.000000  Default  27.0000  27.0000\n",
       "78          that  2394.000000  2394.000000  Default  26.0000  26.0000\n",
       "..           ...          ...          ...      ...      ...      ...\n",
       "74        rights   462.187058  1565.084042   Topic3  -5.0096   0.1466\n",
       "23   application   525.019514  3012.160766   Topic3  -4.8821  -0.3806\n",
       "94          with   434.025195  1553.152349   Topic3  -5.0725   0.0914\n",
       "63            no   427.296131  1542.910320   Topic3  -5.0881   0.0824\n",
       "49    government   451.755430  2932.011317   Topic3  -5.0324  -0.5040\n",
       "\n",
       "[258 rows x 6 columns], token_table=      Topic      Freq Term\n",
       "term                      \n",
       "0         1  0.380203    (\n",
       "0         2  0.349756    (\n",
       "0         3  0.270116    (\n",
       "1         1  0.386394    )\n",
       "1         2  0.343138    )\n",
       "...     ...       ...  ...\n",
       "99        2  0.291593    “\n",
       "99        3  0.253253    “\n",
       "100       1  0.493591    ”\n",
       "100       2  0.332564    ”\n",
       "100       3  0.173808    ”\n",
       "\n",
       "[444 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 2, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy Leakage Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Privacy: Defining the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "\n",
    "real_texts = load_from_disk('./data/generator/data/tab')\n",
    "real_texts = real_texts['train']\n",
    "synth_df = pd.read_csv(synthetic_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = []\n",
    "for i in real_texts['annotations']:\n",
    "    try:\n",
    "        for annotator in i:\n",
    "            for entity in i[annotator]['entity_mentions']:\n",
    "                if(entity['entity_type'] in ['PERSON', 'DATETIME']):\n",
    "                    entities.append(entity['span_text'])\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2990\n"
     ]
    }
   ],
   "source": [
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating leakage of entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syntheval.eval.privacy.metrics import entity_leakage, search_and_compute_EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_leakage, privacy_analysis = entity_leakage(synth_df['output_text'].tolist(), entities, 'privacy-leakage.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of leaked entities: 1.801 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of leaked entities: {100*total_leakage:.3f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating span memorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this only for 15 entities as it is time-intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = entities[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 10\n",
      "Total number of entities 2990\n"
     ]
    }
   ],
   "source": [
    "t_df = pd.DataFrame({'text': synth_df['output_text'].tolist()[:10]})\n",
    "\n",
    "\n",
    "search_and_compute_EPO(synth_file = synth_df, ref_file = t_df, \n",
    "                       synth_phrase_file_path = 'synth-outputs.csv', ref_phrase_file_path = 'ref-outputs.csv',\n",
    "                       entity_patterns = fake_entities, max_window_len = 3,\n",
    "                       text_field = text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of leaked entity contexts: 9.306 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of leaked entity contexts: {100*total_leakage:.3f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Evaluation Against Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kramesh3/.local/lib/python3.9/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "2025-03-21 16:28:51.622122: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742588931.640903   93933 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742588931.646692   93933 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 16:28:51.668562: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from syntheval.eval.text_quality.metrics import TextQualityEval\n",
    "from syntheval.eval.text_quality.arguments import MauveArgs, LMArgs, FrechetArgs\n",
    "from dataclasses import dataclass\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "df = pd.DataFrame({})\n",
    "synthetic_samples = pd.read_csv(synthetic_data_path)\n",
    "real_samples = load_from_disk('./data/generator/data/tab')\n",
    "len_samples = len(synthetic_samples) if len(synthetic_samples)<len(real_samples['train']) else len(real_samples['train'])\n",
    "synthetic_samples = synthetic_samples.head(len_samples)\n",
    "real_samples = real_samples['train'].select(range(len_samples))\n",
    "\n",
    "df['source'] = synthetic_samples['output_text']\n",
    "df['reference'] = real_samples['text']\n",
    "\n",
    "@dataclass\n",
    "class args_temp:\n",
    "    FrechetArgs:FrechetArgs\n",
    "    MauveArgs:MauveArgs\n",
    "    LMArgs:LMArgs\n",
    "\n",
    "args_ = args_temp(FrechetArgs, MauveArgs, LMArgs)\n",
    "qual_estimator = TextQualityEval(args_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/kramesh3/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--perplexity/8ab643ad86f568b7d1d5f7822373fa7401ff5ff0297ccf114b0ca6a33be96bc0 (last modified on Thu Dec 19 16:22:06 2024) since it couldn't be found locally at evaluate-metric--perplexity, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d73292bf5b4cf097be4b665d6871f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qual_estimator.calculate_perplexity(df)\n",
    "qual_estimator.calculate_fid_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated Open-Ended Text Evaluation Metrics:\n",
      "+-------+------------+\n",
      "|  fid  | perplexity |\n",
      "+-------+------------+\n",
      "| 0.771 |   16.846   |\n",
      "+-------+------------+\n"
     ]
    }
   ],
   "source": [
    "qual_estimator.print_metrics(qual_estimator.return_results())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
